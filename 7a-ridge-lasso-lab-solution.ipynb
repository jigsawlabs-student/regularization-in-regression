{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice working with both ridge and lasso regression.  As we'll see ridge regression has the effect of reducing the *size* of our coefficients, while lasso regression tends to zero out coefficients, and thus perform a degree of feature selection for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, we'll be working with data from a iphone app company.  As we'll see the company produces different applications and wants to predict the lifetime value of customers given a stream of purchases.  Because the lifetime value of a customer technically has no end date, instead we will calculate the total revenue collected from a customer 30 days after downloading an application.\n",
    "\n",
    "Let's get started by loading up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can find the data by downloading it [here](https://drive.google.com/file/d/1XwEWgvPj31fflN94tGeCIFLZjV-CDNPE/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then read it in as a csv with something like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./ltv_prediction_demo_data.csv.gz', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idApp</th>\n",
       "      <th>dt</th>\n",
       "      <th>ltvDay1</th>\n",
       "      <th>ltvDay2</th>\n",
       "      <th>ltvDay3</th>\n",
       "      <th>ltvDay4</th>\n",
       "      <th>ltvDay5</th>\n",
       "      <th>ltvDay6</th>\n",
       "      <th>ltvDay7</th>\n",
       "      <th>ltvDay8</th>\n",
       "      <th>ltvDay30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2190000</td>\n",
       "      <td>2190000</td>\n",
       "      <td>2190000</td>\n",
       "      <td>5780000</td>\n",
       "      <td>5780000</td>\n",
       "      <td>5780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idApp          dt  ltvDay1  ltvDay2  ltvDay3  ltvDay4  ltvDay5  ltvDay6  \\\n",
       "0    279  2018-02-18        0        0        0  2190000  2190000  2190000   \n",
       "1    279  2018-04-20        0        0        0        0        0        0   \n",
       "\n",
       "   ltvDay7  ltvDay8  ltvDay30  \n",
       "0  5780000  5780000   5780000  \n",
       "1        0        0         0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]\n",
    "\n",
    "# \tidApp\tdt\tltvDay1\tltvDay2\tltvDay3\tltvDay4\tltvDay5\tltvDay6\tltvDay7\tltvDay8\tltvDay30\n",
    "# 0\t279\t2018-02-18\t0\t0\t0\t2190000\t2190000\t2190000\t5780000\t5780000\t5780000\n",
    "# 1\t279\t2018-04-20\t0\t0\t0\t0\t0\t0\t0\t0\t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324150, 11)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "\n",
    "# (3324150, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a lot of data here.  Each row represents a different user, and the `dt` marks the date that the app was downloaded.\n",
    "\n",
    "Let's narrow our data by trying to make predictions for just a single app.  Use valuecounts to get a sense of the downloads for each of the applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5620     1077387\n",
       "279       532735\n",
       "5619      484202\n",
       "278       282209\n",
       "313       221160\n",
       "          ...   \n",
       "50357          1\n",
       "5570           1\n",
       "50458          1\n",
       "5494           1\n",
       "5548           1\n",
       "Name: idApp, Length: 130, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['idApp'].value_counts()\n",
    "\n",
    "# 5620     1077387\n",
    "# 279       532735\n",
    "# 5619      484202\n",
    "# 278       282209\n",
    "# 313       221160\n",
    "#           ...   \n",
    "# 50357          1\n",
    "# 5570           1\n",
    "# 50458          1\n",
    "# 5494           1\n",
    "# 5548           1\n",
    "# Name: idApp, Length: 130, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that one of the top apps is the app with id `279`.  Let's select the records just of that app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app = df[df['idApp'] == 279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532735, 11)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app.shape\n",
    "# (532735, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because our data has a time component to it, let's sort our data by the `dt` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_sorted = df_app.sort_values('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idApp</th>\n",
       "      <th>dt</th>\n",
       "      <th>ltvDay1</th>\n",
       "      <th>ltvDay2</th>\n",
       "      <th>ltvDay3</th>\n",
       "      <th>ltvDay4</th>\n",
       "      <th>ltvDay5</th>\n",
       "      <th>ltvDay6</th>\n",
       "      <th>ltvDay7</th>\n",
       "      <th>ltvDay8</th>\n",
       "      <th>ltvDay30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>959172</th>\n",
       "      <td>279</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276944</th>\n",
       "      <td>279</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>3872692</td>\n",
       "      <td>11902781</td>\n",
       "      <td>11902781</td>\n",
       "      <td>153992377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idApp          dt  ltvDay1  ltvDay2  ltvDay3  ltvDay4  ltvDay5  \\\n",
       "959172     279  2017-06-18        0        0  3872692  3872692  3872692   \n",
       "3276944    279  2017-06-18        0  3872692  3872692  3872692  3872692   \n",
       "\n",
       "         ltvDay6   ltvDay7   ltvDay8   ltvDay30  \n",
       "959172   3872692   3872692   3872692    3872692  \n",
       "3276944  3872692  11902781  11902781  153992377  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app_sorted[:2]\n",
    "\n",
    "# \tidApp\tdt\tltvDay1\tltvDay2\tltvDay3\tltvDay4\tltvDay5\tltvDay6\tltvDay7\tltvDay8\tltvDay30\n",
    "# 959172\t279\t2017-06-18\t0\t0\t3872692\t3872692\t3872692\t3872692\t3872692\t3872692\t3872692\n",
    "# 3276944\t279\t2017-06-18\t0\t3872692\t3872692\t3872692\t3872692\t3872692\t11902781\t11902781\t153992377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll add the `add_datepart` function in here to perform some basic feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def add_datepart(df, fldname, drop=True, time=False, errors=\"raise\"):\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(df_app_sorted, 'dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling the `add_datepart` function, our data should look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idApp', 'ltvDay1', 'ltvDay2', 'ltvDay3', 'ltvDay4', 'ltvDay5',\n",
       "       'ltvDay6', 'ltvDay7', 'ltvDay8', 'ltvDay30', 'dtYear', 'dtMonth',\n",
       "       'dtWeek', 'dtDay', 'dtDayofweek', 'dtDayofyear', 'dtIs_month_end',\n",
       "       'dtIs_month_start', 'dtIs_quarter_end', 'dtIs_quarter_start',\n",
       "       'dtIs_year_end', 'dtIs_year_start', 'dtElapsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app_sorted.columns\n",
    "\n",
    "# Index(['idApp', 'ltvDay1', 'ltvDay2', 'ltvDay3', 'ltvDay4', 'ltvDay5',\n",
    "#        'ltvDay6', 'ltvDay7', 'ltvDay8', 'ltvDay30', 'dtYear', 'dtMonth',\n",
    "#        'dtWeek', 'dtDay', 'dtDayofweek', 'dtDayofyear', 'dtIs_month_end',\n",
    "#        'dtIs_month_start', 'dtIs_quarter_end', 'dtIs_quarter_start',\n",
    "#        'dtIs_year_end', 'dtIs_year_start', 'dtElapsed'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's separate our data into X and y.  Our variable X should have every column except `idApp` and `ltvDay30` and the variable `y` should just be the column `ltvDay30`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_app_sorted.drop(columns = ['idApp', 'ltvDay30'])\n",
    "y = df_app_sorted['ltvDay30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's separate our data into training, valudation and test data.  We can allocate 10 percent of our data for validation and testing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, shuffle = False)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size = .5, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by using a normal linear regression model.  Fit the linear regression model and score it on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86370730288396"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's use the ridge cv model.  As we know the ridge cv model is designed to reduce the variance in our model by reducing the size of our model's coefficients.  Let's begin by defining a list of alphas, 20 of them evenly spaced from `.001` to `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.16, 0.32, 0.47, 0.63, 0.79, 0.95, 1.11, 1.26, 1.42, 1.58,\n",
       "       1.74, 1.9 , 2.05, 2.21, 2.37, 2.53, 2.68, 2.84, 3.  ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.linspace(.001, 3, 20)\n",
    "alphas.round(2)\n",
    "\n",
    "# array([0.  , 0.16, 0.32, 0.47, 0.63, 0.79, 0.95, 1.11, 1.26, 1.42, 1.58,\n",
    "#        1.74, 1.9 , 2.05, 2.21, 2.37, 2.53, 2.68, 2.84, 3.  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the RidgeCV model to find the value of alpha the performs the best.  To ensure that we are performing cross validation properly, let's use a TimeSeriesSplit.  Make sure to set `normalize = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636962814979466"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphas, normalize = True, cv = TimeSeriesSplit())\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "ridge_model.score(X_validate, y_validate)\n",
    "# 0.8636962814979466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the alpha value that was used to optimize the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it was the lowest alpha value, so apparently we were unable to improve our score using ridge regression.  Still let's initialize a series were we look at the coefficients of our ridge regression model along with the corresponding feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ltvDay1                    -0.03\n",
       "ltvDay2                    -0.02\n",
       "ltvDay3                    -0.06\n",
       "ltvDay4                     0.03\n",
       "ltvDay5                    -0.23\n",
       "ltvDay6                     0.05\n",
       "ltvDay7                     0.02\n",
       "ltvDay8                     1.24\n",
       "dtYear                 672033.55\n",
       "dtMonth                109449.66\n",
       "dtWeek                  -8820.19\n",
       "dtDay                   15602.74\n",
       "dtDayofweek            -47902.52\n",
       "dtDayofyear             -1272.18\n",
       "dtIs_month_end        -879266.70\n",
       "dtIs_month_start      1570141.45\n",
       "dtIs_quarter_end      1824947.16\n",
       "dtIs_quarter_start   -2835222.54\n",
       "dtIs_year_end        -2763302.47\n",
       "dtIs_year_start       6920864.75\n",
       "dtElapsed                   0.10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coef = pd.Series(ridge_model.coef_, X_validate.columns)\n",
    "ridge_coef.round(2)\n",
    "\n",
    "# ltvDay1                    -0.03\n",
    "# ltvDay2                    -0.02\n",
    "# ltvDay3                    -0.06\n",
    "# ltvDay4                     0.03\n",
    "# ltvDay5                    -0.23\n",
    "# ltvDay6                     0.05\n",
    "# ltvDay7                     0.02\n",
    "# ltvDay8                     1.24\n",
    "# dtYear                 672033.55\n",
    "# dtMonth                109449.66\n",
    "# dtWeek                  -8820.19\n",
    "# dtDay                   15602.74\n",
    "# dtDayofweek            -47902.52\n",
    "# dtDayofyear             -1272.18\n",
    "# dtIs_month_end        -879266.70\n",
    "# dtIs_month_start      1570141.45\n",
    "# dtIs_quarter_end      1824947.16\n",
    "# dtIs_quarter_start   -2835222.54\n",
    "# dtIs_year_end        -2763302.47\n",
    "# dtIs_year_start       6920864.75\n",
    "# dtElapsed                   0.10\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move to lasso regression.  We defined a set of alpha values for you.  Make sure to use `TimeSeriesSplit` for our cross validation.  In addition to `normalize = True`, set the number of iterations to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(.01, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.833496630644125e+20, tolerance: 1.097001221124991e+18\n",
      "  tol, rng, random, positive)\n",
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.44433118486004e+20, tolerance: 1.1232684272503066e+18\n",
      "  tol, rng, random, positive)\n",
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.857653852255354e+20, tolerance: 1.3370233775554412e+18\n",
      "  tol, rng, random, positive)\n",
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1175335065952295e+20, tolerance: 1.3178019813449037e+18\n",
      "  tol, rng, random, positive)\n",
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.568123335773318e+20, tolerance: 1.3178019813449037e+18\n",
      "  tol, rng, random, positive)\n",
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.401826618140294e+20, tolerance: 1.2881561848509985e+18\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
       "       2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
       "        max_iter=5000, normalize=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphas, normalize = True, max_iter = 5000)\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# LassoCV(alphas=array([0.01      , 0.56444444, 1.11888889, 1.67333333, 2.22777778,\n",
    "#        2.78222222, 3.33666667, 3.89111111, 4.44555556, 5.        ]),\n",
    "#         max_iter=5000, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8637338145608716"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.score(X_validate, y_validate)\n",
    "\n",
    "# 0.8637231479045426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we performed essentially as well as the our linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's again look at the value of alpha that was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.alpha_\n",
    "# 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And notice that our model did manage to zero out certain features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef = pd.Series(lasso_model.coef_, X_validate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtWeek                0.000000e+00\n",
       "dtDayofyear           0.000000e+00\n",
       "dtMonth               0.000000e+00\n",
       "ltvDay2               1.367119e-02\n",
       "ltvDay1               2.546847e-02\n",
       "ltvDay4               3.998085e-02\n",
       "ltvDay3               5.769050e-02\n",
       "ltvDay6               6.592506e-02\n",
       "ltvDay7               8.225642e-02\n",
       "dtElapsed             1.152870e-01\n",
       "ltvDay5               2.511533e-01\n",
       "ltvDay8               1.335798e+00\n",
       "dtDay                 1.150842e+04\n",
       "dtDayofweek           4.859411e+04\n",
       "dtYear                2.801050e+05\n",
       "dtIs_month_end        8.144355e+05\n",
       "dtIs_month_start      1.555152e+06\n",
       "dtIs_quarter_end      1.700133e+06\n",
       "dtIs_year_end         2.608323e+06\n",
       "dtIs_quarter_start    2.727256e+06\n",
       "dtIs_year_start       6.766724e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(lasso_coef).sort_values(ascending = True)\n",
    "\n",
    "# dtWeek                0.000000e+00\n",
    "# dtDayofyear           0.000000e+00\n",
    "# dtMonth               0.000000e+00\n",
    "# ltvDay2               1.367119e-02\n",
    "# ltvDay1               2.546847e-02\n",
    "# ltvDay4               3.998085e-02\n",
    "# ltvDay3               5.769050e-02\n",
    "# ltvDay6               6.592506e-02\n",
    "# ltvDay7               8.225642e-02\n",
    "# dtElapsed             1.152870e-01\n",
    "# ltvDay5               2.511533e-01\n",
    "# ltvDay8               1.335798e+00\n",
    "# dtDay                 1.150842e+04\n",
    "# dtDayofweek           4.859411e+04\n",
    "# dtYear                2.801050e+05\n",
    "# dtIs_month_end        8.144355e+05\n",
    "# dtIs_month_start      1.555152e+06\n",
    "# dtIs_quarter_end      1.700133e+06\n",
    "# dtIs_year_end         2.608323e+06\n",
    "# dtIs_quarter_start    2.727256e+06\n",
    "# dtIs_year_start       6.766724e+06\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw how we can use both ridge and lasso regression to reduce the amount of variance in our model.  We saw that because decreasing variance comes with a tradeoff to bias, we did not necessarily improve upon our linear regression model, when working with this data.  Still, we saw that we could use lasso regression to achieve similar performance to our linear regression model, while reducing the number of features that we use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
