{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance In Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll return to the topic of where error comes from in machine learning models.  Remember that we have error whenever our machine learning model makes a prediction different from the actual outcome.  And in regression problems, we have used SSE or MSE to quantify this error.  \n",
    "\n",
    "### Reviewing sources of error\n",
    "\n",
    "We have also identified the three sources of error.   \n",
    "\n",
    "1. Irreducible error - this is from randomness in our future or holdout data.  We cannot predict this randomness, and thus we will always have an amount of irreducible error.\n",
    "\n",
    "2. Variance - this is from randomness in our training data.  Our model fits to the training data, and as it fits to randomness in our training data, we train an incorrect model, which varies as the training data varies.\n",
    "\n",
    "3. Bias - this is a systematic problem that persists over the long run.  It could be due to a problem in our training data (like using an unrepresentative dataset).  In linear regression, it often refers to ommitted variable bias, or underfitting, where our model is not flexible enough to discover the underlying pattern producing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll focus on regularization, which is a technique for reducing variance in linear models.  Remember variance occurs when our models are too flexible and thus overfit to the randomness in the data.  One technique, for handling variance is simply to remove the less important features.\n",
    "\n",
    "In linear models, the variance can also be due to multicollinearity.  Remember that multicollinearity occurs when we have highly correlated features.  When that occurs, the model will see a similar effect as both features change similarly.  And from model to model will attribute this effect differently.  \n",
    "\n",
    "Let's see this with our Airbnb data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading up our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/regularization-in-regression/master/listings_train_df.csv\"\n",
    "df = pd.read_csv(url, index_col = 0)\n",
    "df_subset = df[df['price'] < 320]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove listings who are outliers, with prices over 320 dollars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = df.drop('price', axis = 1)\n",
    "y_train = np.log(df['price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load up the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/regularization-in-regression/master/listings_test_df.csv\"\n",
    "df_test = pd.read_csv(url, index_col = 0)\n",
    "X_test =  df_test.drop('price', axis = 1)\n",
    "y_test = np.log(df_test['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded our data, let's train multiple models and see how the coefficients of our parameters change from model to model.  The larger the change, the larger the difference in our models and the higher our variance.  Eventually, we'll try to reduce the variance in coefficients that change the most.\n",
    "\n",
    "Now one issue we have is that larger coefficients will have larger changes from model to model.  And these larger coefficients will depend on the scale of the underlying data (remember that there is a difference between increasing a listing by one foot and by one meter).\n",
    "\n",
    "So let's begin by scaling our data.  And then we'll fit ten different models on different samples of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "transformed_X = pd.DataFrame(scaler.fit_transform(X_train), \n",
    "                             columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>...</th>\n",
       "      <th>first_reviewWeek_is_na</th>\n",
       "      <th>first_reviewDay_is_na</th>\n",
       "      <th>first_reviewDayofweek_is_na</th>\n",
       "      <th>first_reviewDayofyear_is_na</th>\n",
       "      <th>last_reviewYear_is_na</th>\n",
       "      <th>last_reviewMonth_is_na</th>\n",
       "      <th>last_reviewWeek_is_na</th>\n",
       "      <th>last_reviewDay_is_na</th>\n",
       "      <th>last_reviewDayofweek_is_na</th>\n",
       "      <th>last_reviewDayofyear_is_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008381</td>\n",
       "      <td>-0.165645</td>\n",
       "      <td>-0.391608</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>-0.792188</td>\n",
       "      <td>1.621270</td>\n",
       "      <td>0.151553</td>\n",
       "      <td>0.587728</td>\n",
       "      <td>-0.420238</td>\n",
       "      <td>-0.395254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458112</td>\n",
       "      <td>-0.458112</td>\n",
       "      <td>-0.458112</td>\n",
       "      <td>-0.458112</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.457578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.194988</td>\n",
       "      <td>0.526644</td>\n",
       "      <td>-0.391608</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>-0.792188</td>\n",
       "      <td>-0.250794</td>\n",
       "      <td>0.377464</td>\n",
       "      <td>0.587728</td>\n",
       "      <td>-0.420238</td>\n",
       "      <td>-0.395254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.182873</td>\n",
       "      <td>2.182873</td>\n",
       "      <td>2.182873</td>\n",
       "      <td>2.182873</td>\n",
       "      <td>2.185420</td>\n",
       "      <td>2.185420</td>\n",
       "      <td>2.185420</td>\n",
       "      <td>2.185420</td>\n",
       "      <td>2.185420</td>\n",
       "      <td>2.185420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   host_id  host_is_superhost  host_has_profile_pic  \\\n",
       "0  0.008381 -0.165645          -0.391608              0.060282   \n",
       "1 -0.194988  0.526644          -0.391608              0.060282   \n",
       "\n",
       "   host_identity_verified  latitude  longitude  is_location_exact  \\\n",
       "0               -0.792188  1.621270   0.151553           0.587728   \n",
       "1               -0.792188 -0.250794   0.377464           0.587728   \n",
       "\n",
       "   accommodates  guests_included  ...  first_reviewWeek_is_na  \\\n",
       "0     -0.420238        -0.395254  ...               -0.458112   \n",
       "1     -0.420238        -0.395254  ...                2.182873   \n",
       "\n",
       "   first_reviewDay_is_na  first_reviewDayofweek_is_na  \\\n",
       "0              -0.458112                    -0.458112   \n",
       "1               2.182873                     2.182873   \n",
       "\n",
       "   first_reviewDayofyear_is_na  last_reviewYear_is_na  last_reviewMonth_is_na  \\\n",
       "0                    -0.458112              -0.457578               -0.457578   \n",
       "1                     2.182873               2.185420                2.185420   \n",
       "\n",
       "   last_reviewWeek_is_na  last_reviewDay_is_na  last_reviewDayofweek_is_na  \\\n",
       "0              -0.457578             -0.457578                   -0.457578   \n",
       "1               2.185420              2.185420                    2.185420   \n",
       "\n",
       "   last_reviewDayofyear_is_na  \n",
       "0                   -0.457578  \n",
       "1                    2.185420  \n",
       "\n",
       "[2 rows x 321 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price\n",
       "0  3.496508\n",
       "1  3.218876"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reset_index()[['price']]\n",
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_models = []\n",
    "samples = []\n",
    "for i in range(10):\n",
    "    X_sample = transformed_X.sample(15000, random_state = i)\n",
    "    y_sample = y_train.loc[X_sample.index]\n",
    "    model = LinearRegression().fit(X_sample, y_sample)\n",
    "    linear_models.append(model)\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the coefficients in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>...</th>\n",
       "      <th>first_reviewWeek_is_na</th>\n",
       "      <th>first_reviewDay_is_na</th>\n",
       "      <th>first_reviewDayofweek_is_na</th>\n",
       "      <th>first_reviewDayofyear_is_na</th>\n",
       "      <th>last_reviewYear_is_na</th>\n",
       "      <th>last_reviewMonth_is_na</th>\n",
       "      <th>last_reviewWeek_is_na</th>\n",
       "      <th>last_reviewDay_is_na</th>\n",
       "      <th>last_reviewDayofweek_is_na</th>\n",
       "      <th>last_reviewDayofyear_is_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>-0.026930</td>\n",
       "      <td>-0.004180</td>\n",
       "      <td>0.155194</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>...</td>\n",
       "      <td>-329.758153</td>\n",
       "      <td>-329.758153</td>\n",
       "      <td>-329.758153</td>\n",
       "      <td>-329.758153</td>\n",
       "      <td>5.656180e+10</td>\n",
       "      <td>5.656180e+10</td>\n",
       "      <td>5.656180e+10</td>\n",
       "      <td>-1.243829e+11</td>\n",
       "      <td>-1.082791e+11</td>\n",
       "      <td>6.297654e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>-0.020208</td>\n",
       "      <td>-0.003340</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.044605</td>\n",
       "      <td>...</td>\n",
       "      <td>-376.873147</td>\n",
       "      <td>-376.873147</td>\n",
       "      <td>-376.873147</td>\n",
       "      <td>-376.873147</td>\n",
       "      <td>1.929515e+10</td>\n",
       "      <td>1.929515e+10</td>\n",
       "      <td>1.929515e+10</td>\n",
       "      <td>-3.357016e+10</td>\n",
       "      <td>-6.222693e+10</td>\n",
       "      <td>3.791165e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.015451</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>-0.001455</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>-0.024528</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.154365</td>\n",
       "      <td>0.045218</td>\n",
       "      <td>...</td>\n",
       "      <td>-312.932209</td>\n",
       "      <td>-312.931768</td>\n",
       "      <td>-312.931768</td>\n",
       "      <td>-312.931768</td>\n",
       "      <td>-1.837808e+10</td>\n",
       "      <td>-1.837808e+10</td>\n",
       "      <td>-1.837808e+10</td>\n",
       "      <td>7.082893e+09</td>\n",
       "      <td>4.078706e+10</td>\n",
       "      <td>7.264285e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>-0.028299</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>0.153036</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>...</td>\n",
       "      <td>-362.684512</td>\n",
       "      <td>-362.684512</td>\n",
       "      <td>-362.684512</td>\n",
       "      <td>-362.684512</td>\n",
       "      <td>1.513171e+09</td>\n",
       "      <td>1.513171e+09</td>\n",
       "      <td>1.513171e+09</td>\n",
       "      <td>-2.954910e+09</td>\n",
       "      <td>-8.089877e+08</td>\n",
       "      <td>-7.756140e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>-0.019772</td>\n",
       "      <td>-0.003379</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>...</td>\n",
       "      <td>-315.919063</td>\n",
       "      <td>-315.919063</td>\n",
       "      <td>-315.919063</td>\n",
       "      <td>-315.919063</td>\n",
       "      <td>-8.050963e+09</td>\n",
       "      <td>-8.050963e+09</td>\n",
       "      <td>-8.050963e+09</td>\n",
       "      <td>2.038013e+10</td>\n",
       "      <td>1.624912e+10</td>\n",
       "      <td>-1.247635e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   host_id  host_is_superhost  host_has_profile_pic  \\\n",
       "0  0.015274  0.019837           0.013542              0.001779   \n",
       "1  0.017324  0.014383           0.013798              0.000096   \n",
       "2  0.014882  0.015451           0.016353             -0.001455   \n",
       "3  0.008907  0.021261           0.014576             -0.000664   \n",
       "4  0.014148  0.016540           0.014186              0.000649   \n",
       "\n",
       "   host_identity_verified  latitude  longitude  is_location_exact  \\\n",
       "0                0.000676  0.010243  -0.026930          -0.004180   \n",
       "1                0.002851  0.015629  -0.020208          -0.003340   \n",
       "2                0.003948  0.004409  -0.024528          -0.004426   \n",
       "3                0.003518  0.003209  -0.028299          -0.005408   \n",
       "4               -0.000865  0.009958  -0.019772          -0.003379   \n",
       "\n",
       "   accommodates  guests_included  ...  first_reviewWeek_is_na  \\\n",
       "0      0.155194         0.048866  ...             -329.758153   \n",
       "1      0.153367         0.044605  ...             -376.873147   \n",
       "2      0.154365         0.045218  ...             -312.932209   \n",
       "3      0.153036         0.045907  ...             -362.684512   \n",
       "4      0.149927         0.048519  ...             -315.919063   \n",
       "\n",
       "   first_reviewDay_is_na  first_reviewDayofweek_is_na  \\\n",
       "0            -329.758153                  -329.758153   \n",
       "1            -376.873147                  -376.873147   \n",
       "2            -312.931768                  -312.931768   \n",
       "3            -362.684512                  -362.684512   \n",
       "4            -315.919063                  -315.919063   \n",
       "\n",
       "   first_reviewDayofyear_is_na  last_reviewYear_is_na  last_reviewMonth_is_na  \\\n",
       "0                  -329.758153           5.656180e+10            5.656180e+10   \n",
       "1                  -376.873147           1.929515e+10            1.929515e+10   \n",
       "2                  -312.931768          -1.837808e+10           -1.837808e+10   \n",
       "3                  -362.684512           1.513171e+09            1.513171e+09   \n",
       "4                  -315.919063          -8.050963e+09           -8.050963e+09   \n",
       "\n",
       "   last_reviewWeek_is_na  last_reviewDay_is_na  last_reviewDayofweek_is_na  \\\n",
       "0           5.656180e+10         -1.243829e+11               -1.082791e+11   \n",
       "1           1.929515e+10         -3.357016e+10               -6.222693e+10   \n",
       "2          -1.837808e+10          7.082893e+09                4.078706e+10   \n",
       "3           1.513171e+09         -2.954910e+09               -8.089877e+08   \n",
       "4          -8.050963e+09          2.038013e+10                1.624912e+10   \n",
       "\n",
       "   last_reviewDayofyear_is_na  \n",
       "0                6.297654e+10  \n",
       "1                3.791165e+10  \n",
       "2                7.264285e+09  \n",
       "3               -7.756140e+08  \n",
       "4               -1.247635e+10  \n",
       "\n",
       "[5 rows x 321 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "stacked_coef = np.vstack([model.coef_ for model in linear_models])\n",
    "coef_df = pd.DataFrame(stacked_coef, columns = X_sample.columns)\n",
    "coef_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of the coefficients stay fairly consistent.  Others appear to widely vary.  For example, take a look at how some of the `is_na` columns vary between model and model.  It's hard to know which to believe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, remember that variance in our model is a sign of our model overfitting to the randomness in the data.  We can quantify this variance, by well looking at the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            6.162351e-06\n",
       "host_id                       8.447565e-06\n",
       "host_is_superhost             2.103953e-06\n",
       "host_has_profile_pic          1.162555e-06\n",
       "host_identity_verified        3.969869e-06\n",
       "                                  ...     \n",
       "last_reviewMonth_is_na        1.181411e+21\n",
       "last_reviewWeek_is_na         1.181411e+21\n",
       "last_reviewDay_is_na          9.984990e+22\n",
       "last_reviewDayofweek_is_na    1.322295e+22\n",
       "last_reviewDayofyear_is_na    1.318559e+23\n",
       "Length: 321, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that variance occurs when we are overfitting to the randomness in the training data.  We can see by looking at how our models perform on the training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "\n",
    "for model, sample in zip(linear_models, samples):\n",
    "    X_sample_train, y_sample_train = sample\n",
    "    score = model.score(X_sample_train, y_sample_train)\n",
    "    train_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5942207451864707, 0.5943320145546616, 0.592339544092867, 0.5953252833742946]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we see that from model to model, we have fairly high scores on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for model in linear_models:\n",
    "    score = model.score(transformed_X_test, y_test)\n",
    "    test_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.3704105317150126e+18,\n",
       " -1.2493879652347668e+18,\n",
       " -2.472987605610295e+18,\n",
       " -1.357788129732622e+16]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the high scores we saw on the training data do not generalize to our test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combatting Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lessons that follow, we'll see a potential solution to variance: regularizing our linear model.  We'll see exactly what this means and how it works in future lessons, but for now, let's just see it's effectiveness.  \n",
    "\n",
    "We'll use a model called ridge regression.  Ridge regression takes a hyperparameter called alpha, which we'll initialize and pass through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.06040404, 0.11080808])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.linspace(.01, 5, 100)\n",
    "alphas[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's our model and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916016838506353"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas = alphas)\n",
    "ridge.fit(transformed_X, y_train).score(transformed_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have a model that performs *slightly* worse on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5835320993438434"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it generalizes much better to our holdout data.  In the lessons that follow we'll see how this technique works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we reviewed the sources of error and the problem of variance in our models.  Our models suffer from variance when they are overfit to the error in the data. Our models are more susceptible to this error when they become overly flexible, due to many features, and multicollinearity.  \n",
    "\n",
    "We saw this variance by fitting multiple models on different subsets of the same training data.  We saw high degrees of variance in the coefficients of our parameters, and we saw models that did not generalize to our holdout data.  Finally, we saw how, somehow, ridge regression could allow us to train a model that did generalize."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
