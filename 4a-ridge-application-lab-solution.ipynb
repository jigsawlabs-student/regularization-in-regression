{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll explore ridge regression as applied to the diabetes dataset in sklearn.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our diabetes data from the sklearn datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = pd.DataFrame(diabetes['data'], columns = diabetes['feature_names'])\n",
    "y = pd.Series(diabetes['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by split our training and test data with a `test_size` of `.2`, and a `random_state` of `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = .2,\n",
    "                                                    random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we use ridge regression, we'll need to ensure that all of our features are scaled similarly.  \n",
    "\n",
    "> Remember that ridge regression works by finding penalizing features that have larger magnitude, so we want to make sure that all features are on a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's begin by scaling our training data.  Use the standard scaler to scale the data in `X_train`, and reassign the data to a pandas dataframe with the correct columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800500</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>1.297088</td>\n",
       "      <td>0.459840</td>\n",
       "      <td>-0.929746</td>\n",
       "      <td>-0.732065</td>\n",
       "      <td>-0.912451</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.418551</td>\n",
       "      <td>-0.370989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039567</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-1.082180</td>\n",
       "      <td>-0.553511</td>\n",
       "      <td>-0.177624</td>\n",
       "      <td>-0.402886</td>\n",
       "      <td>1.564414</td>\n",
       "      <td>-0.830301</td>\n",
       "      <td>-1.436551</td>\n",
       "      <td>-1.938479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.793307</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>0.934533</td>\n",
       "      <td>-0.119218</td>\n",
       "      <td>-0.958674</td>\n",
       "      <td>-0.718897</td>\n",
       "      <td>-0.680245</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>-0.545154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.800500  1.065488  1.297088  0.459840 -0.929746 -0.732065 -0.912451   \n",
       "1 -0.039567 -0.938537 -1.082180 -0.553511 -0.177624 -0.402886  1.564414   \n",
       "2  1.793307  1.065488  0.934533 -0.119218 -0.958674 -0.718897 -0.680245   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.054499  0.418551 -0.370989  \n",
       "1 -0.830301 -1.436551 -1.938479  \n",
       "2 -0.054499  0.060207 -0.545154  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns = X.columns)\n",
    "X_transformed_df[:3]\n",
    "\n",
    "# \tage\tsex\tbmi\tbp\ts1\ts2\ts3\ts4\ts5\ts6\n",
    "# 0\t0.800500\t1.065488\t1.297088\t0.459840\t-0.929746\t-0.732065\t-0.912451\t-0.054499\t0.418551\t-0.370989\n",
    "# 1\t-0.039567\t-0.938537\t-1.082180\t-0.553511\t-0.177624\t-0.402886\t1.564414\t-0.830301\t-1.436551\t-1.938479\n",
    "# 2\t1.793307\t1.065488\t0.934533\t-0.119218\t-0.958674\t-0.718897\t-0.680245\t-0.054499\t0.060207\t-0.545154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then use our scaler to transform our data in `X_test`, and let the result be a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.394248</td>\n",
       "      <td>-0.910503</td>\n",
       "      <td>0.117078</td>\n",
       "      <td>0.755914</td>\n",
       "      <td>1.060471</td>\n",
       "      <td>0.703755</td>\n",
       "      <td>1.443097</td>\n",
       "      <td>-0.802763</td>\n",
       "      <td>-0.006593</td>\n",
       "      <td>0.438779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.618727</td>\n",
       "      <td>1.098294</td>\n",
       "      <td>1.688238</td>\n",
       "      <td>1.117483</td>\n",
       "      <td>1.669636</td>\n",
       "      <td>1.406504</td>\n",
       "      <td>0.511315</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.856628</td>\n",
       "      <td>-0.179012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  1.394248 -0.910503  0.117078  0.755914  1.060471  0.703755  1.443097   \n",
       "1 -1.618727  1.098294  1.688238  1.117483  1.669636  1.406504  0.511315   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.802763 -0.006593  0.438779  \n",
       "1  0.002235  0.856628 -0.179012  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "X_test_transformed[:2]\n",
    "\n",
    "\n",
    "# age\tsex\tbmi\tbp\ts1\ts2\ts3\ts4\ts5\ts6\n",
    "# 0\t1.394248\t-0.910503\t0.117078\t0.755914\t1.060471\t0.703755\t1.443097\t-0.802763\t-0.006593\t0.438779\n",
    "# 1\t-1.618727\t1.098294\t1.688238\t1.117483\t1.669636\t1.406504\t0.511315\t0.002235\t0.856628\t-0.179012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# (331, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "# (111, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving onto ridge regression, let's train a linear regression normal linear regression model.  Assign the model to the variable `linear_model`, and fit the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's score the model on both the training data, and then the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5323676737904688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = linear_model.score(X_train_transformed, y_train)\n",
    "train_score\n",
    "# 0.5323676737904688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399387660024644"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = linear_model.score(X_test_transformed, y_test)\n",
    "test_score\n",
    "# 0.4399387660024644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training score is higher than the test score.  This is a sign of our model overfitting to the randomness in the model.  This is a sign of variance in our model, as with different training data, our model's parameters will vary.\n",
    "\n",
    "We know that one symptom of variance in the model is coefficients with a larger magnitude.  Let's measure the magnitude of the coefficients using the L2 norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First we'll assign the coefficients to a series, and sort the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    0.441786\n",
       "s6     2.460215\n",
       "s4     5.809504\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "coef_series = pd.Series(index = X.columns, data = linear_model.coef_)\n",
    "np.abs(coef_series).sort_values(ascending = True)[:3]\n",
    "\n",
    "# age    0.441786\n",
    "# s6     2.460215\n",
    "# s4     5.809504\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that with ridge regression, we measure the magnitude of the coefficients with L2 norm squared.  Calculate the size of the L2 norm squared.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5263.051521586297"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(coef_series**2).sum()\n",
    "\n",
    "# 5263.051521586297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see the L2 norm of the coefficients is a `5263.051521586297`, and that we have a model that has a lower score on the test set than the test set.  We'll use this linear model as a baseline to our ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we've trained our baseline linear regression model, let's see how our ridge regression model compares.  Let's import Ridge from sklearn's linear_model module, and initialize our model with alpha set equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's fit the model to the training data, and assess the score on both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5320698844221448"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_train_transformed, y_train)\n",
    "# 0.5320679342756284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44168863198574837"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_test_transformed, y_test)\n",
    "# 0.4416770567731113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our ridge regression performs slightly better on the test set than our previous model which had a score of `.4399`.  \n",
    "\n",
    "> One reason for the lack of improvement in scores could be a lack of multicollinearity between the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next calculate the L2 norm of the parameters of our ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3789.6597179177006"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ridge.coef_**2).sum()\n",
    "# 3789.1129238233434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our ridge regression model did succeed in reducing the L2 norm of our model's coefficients, as our initial regression model had a \n",
    "an L2 norm of `5263.051521586297`.  We did this to reduce error from variance, which it looks like was achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding our Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one question we may have is how to find the correct value for alpha.  To do so, we treat alpha as a hyperparameter, and we choose alpha by evaluating the performance of our model on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ridge regression, we can use the RidgeCV constructor to perform cross validation for us. \n",
    "\n",
    "> Because we do not have a complicated validation scheme, we do not have to worry about using TimeSeriesSplit, or a custom validation scheme.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `RidgeCV` from our `linear_model` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `RidgeCV` takes a parameter called `alphas` which is a list of all of the alphas it will try out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use linspace to initialize a numpy array of 200 alphas, ranging from `.01` to `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "alphas = np.linspace(.01, 10, 200)\n",
    "\n",
    "alphas.shape\n",
    "# (200,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize the RidgeCV model passing through the list of alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas = alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally call `fit` on ridge_cv, and then call score, passing through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319458627105029"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.fit(X_train_transformed, y_train)\n",
    "ridge_cv.score(X_train_transformed, y_train)\n",
    "\n",
    "# 0.5319458627105029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns to us the score of the model that performed the best, according to cross validation.  Let's see how this model performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44198968565738184"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.score(X_test_transformed, y_test)\n",
    "\n",
    "# 0.44198968565738184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If we did not previously scale our data, ridge regression will do it for us with a call to `RidgeCV(normalize = True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can view the hyperparameter for the model that performed the best with a call to `alpha_`.  Call this on our `ridge_cv` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2650251256281408"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.alpha_\n",
    "\n",
    "# 1.2650251256281408"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the coefficients, by calling `coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.39250354,  -9.61825496,  24.63103684,  16.13971359,\n",
       "       -30.60423022,  17.07655128,   2.13699152,   4.56567086,\n",
       "        36.55650019,   2.51599225])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.coef_\n",
    "# array([ -0.39250354,  -9.61825496,  24.63103684,  16.13971359,\n",
    "#        -30.60423022,  17.07655128,   2.13699152,   4.56567086,\n",
    "#         36.55650019,   2.51599225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw how to train a ridge regression model, and how it compares to our linear regression model.  Because our ridge regression model penalizes parameters with higher coefficients, we first scaled our data using the StandardScaler.  Then, when applying ridge regression we saw that it trained a model with a similar score but with smaller parameters, as assessed by the L2 norm.  \n",
    "\n",
    "Finally, we saw how we can find the correct value of alpha to balance the bias variance tradeoff.  We did so by initializing RidgeCV with a list of alphas, and then finding the value of alpha that best predicted the validation set according to cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
